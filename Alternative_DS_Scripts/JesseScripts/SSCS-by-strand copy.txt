#!/bin/bash

# JS 2/7/16

# Updated 4/26/16 for 160422 run which removes known SNP sites from pileup file before subsequent analysis. This allows turning off depth and clonality cutoff filters.

# This script is for carrying out seperate reference vs anti-reference read analysis on single-end (SE) SSCS data. Doing a seperate analysis on each type of read allows for proper determination of SSCS mutation spectrum. It takes sorted output from aligned read 1 file (must be indexed), copies to new directory within index directory and carries through whole analysis thereafter. It is set up to be easy to simply run after the main script has been done and will put all it's own data in a new subdirectory within an SE index file. To use, just copy it to each index folder and run per below.

# In future consider updating to not trim to BED initially and instead clip pileup files at end
# In future use samtools merge to combine forward mapping reads from both read 1 and read 2 files before processing. Currently only does read 1
# In future perhaps wise to fix the names of all output files to reflect is only processing read 1, not both

# **************************************** SET PATHS AND REFERENCES **********************************************

DCSPATH="/Users/jjsalk/Dropbox/DS-software/DCS-1.28/programs"; export DCSPATH
PICARDPATH="/Users/jjsalk/Dropbox/DS-software/programs/picard-tools-1"; export PICARDPATH
GATKPATH="/Users/jjsalk/Dropbox/DS-software/programs/GenomeAnalysisTK-3.4-46"; export GATKPATH

ALIGNREF="/Users/jjsalk/Dropbox/DS-software/refgenomes/human_g1k_v37/human_g1k_v37.fa"; export ALIGNREF
FINALREF="/Users/jjsalk/Dropbox/DS-software/refgenomes/human_g1k_v37/human_g1k_v37.fa"; export FINALREF
BEDFILE="/Users/jjsalk/Dropbox/DS-software/bedfiles/p53AR.bed"; export BEDFILE

# First is SNP sites to exclude, 2nd set is SNP sites to keep (typically will be the same but coded differently)
SNPPURGE="/Users/jjsalk/Dropbox/DS-software/pileup-processing-scripts/filter_SNPs/p53AR/purge-p53AR-MAF-0.001.script"; export SNPPURGE
SNPSIFT="/Users/jjsalk/Dropbox/DS-software/pileup-processing-scripts/filter_SNPs/p53AR/sift-p53AR-MAF-0.001.script"; export SNPSIFT

# ***************************************** PREPARE WORKSPACE ****************************************************

# Stop on any error inside pipeline or with unassigned variables
clear
set -e
set -o pipefail
set -u

# Run from the index directory containing the previously run data 
# Command line usage: 
# time bash -x SSCS-by-strand.txt 2> SSCS-by-strand.se

# Scripts starts in an index directory (iX)

# Make new directory for analysis, copy in starting file and move to there
mkdir SSCS-by-strand

# **************************************** PROCESS READ 1 FILE ***************************************************

# Copy relevant read 1 files
cp seq1.fq.smi.aln1.sort.bam ./SSCS-by-strand
cp seq1.fq.smi.aln1.sort.bam.bai ./SSCS-by-strand
cd SSCS-by-strand

# Remove all unmapped reads
samtools view -F 0x04 -b seq1.fq.smi.aln1.sort.bam > seq1.fq.smi.aln1.sort.mapped.bam

# Make files with only fwd or reverse mapping reads
samtools view -b -F 16 seq1.fq.smi.aln1.sort.mapped.bam > seq1fwd.bam
samtools view -b -f 16 seq1.fq.smi.aln1.sort.mapped.bam > seq1rev.bam

# Index these
samtools index seq1fwd.bam 
samtools index seq1rev.bam

# Make folder for each and move each plus index file in
mkdir forward
mkdir reverse
mv seq1fwd* ./forward 
mv seq1rev* ./reverse 

# Go for forward directory
cd forward

# Rename each file to match input name for existing intersectbed script step
mv seq1fwd.bam seq1.fq.smi.aln1.sort.bam
mv seq1fwd.bam.bai seq1.fq.smi.aln1.sort.bam.bai

# Pickup existing script here. Does intersect bed step. Makes SSCS with standard criteria and re-aligns to genome.

intersectbed -abam seq1.fq.smi.aln1.sort.bam -b $BEDFILE > seq1-bed.fq.smi.aln1.sort.bam

python $DCSPATH/consensusMaker.py --readlength 84 --infile seq1-bed.fq.smi.aln1.sort.bam --tagfile seq1.tagcounts --fastqfile seq1_sscs.fastq --minmem 3 --maxmem 1000 --cutoff .9 --readnum 1 -p | bwa aln $FINALREF - > seq1_sscs.aln

cat seq1.tagcounts | python $DCSPATH/countField1.py 2| sort -k1,1n > seq1.tagstats

bwa samse $FINALREF seq1_sscs.aln seq1_sscs.fastq > seq1_sscs.sam

samtools view -Sbu seq1_sscs.sam | samtools sort - seq1_sscs.sort

samtools index seq1_sscs.sort.bam

# Because am only procesing read 1, I removed all the read 2 file steps and DCS steps. Normally read 1 and read 2 files get merged. I took this step out and here rename the read1 files to become the seqboth files so names match for input in next steps.

mv  seq1_sscs.sort.bam  seq_both_sscs.bam
mv  seq1_sscs.sort.bam.bai  seq_both_sscs.bam.bai

# Back to normal script. Clip files. This is set to trim 12 from both ends.

java -jar -Xmx2g $PICARDPATH/AddOrReplaceReadGroups.jar INPUT=seq_both_sscs.bam OUTPUT=seq_both_sscs_readgroups.bam RGLB=UW RGPL=Illumina RGPU=ATATAT RGSM=default
samtools index seq_both_sscs_readgroups.bam

java -jar -Xmx8g $GATKPATH/GenomeAnalysisTK.jar -T ClipReads -I seq_both_sscs_readgroups.bam -o seq_both_sscs_clipped.bam -R $FINALREF --cyclesToTrim "73-84,1-12" --clipRepresentation HARDCLIP_BASES --fix_misencoded_quality_scores

samtools index seq_both_sscs_clipped.bam

# Final stats. I removed steps only relevent to DCS. Makes an SSCS pileup first:

samtools mpileup -B -d 500000 -f $FINALREF seq_both_sscs_clipped.bam > seq_both_sscs_clipped.bam.pileup

# Then take normal pileup and use specified file above to remove particular list of SNPs (For example all in P53/AR set with MAF >0.001)

cat seq_both_sscs_clipped.bam.pileup | bash $SNPPURGE > seq_both_sscs_clipped.bam.pileup.noSNP

# Below have changed -d from 20 to 1 (count all sites regardless of depth) and -C from 0.2 to 1 (turn off clonality cutoff). Default N filter is 5% (same). -u is counting uniques only (same)

cat seq_both_sscs_clipped.bam.pileup.noSNP | python $DCSPATH/count-muts.py -d 1 -C 1 -u > seq_both_sscs_clipped.bam.pileup.noSNP.countmuts

# Below have changed -d from 20 to 1 (count all sites regardless of depth). -C remains default of 1 (keep all % muts). N filter unchanged at 1 (no max). No -u (keep all, not just uniques) 

cat seq_both_sscs_clipped.bam.pileup.noSNP | python $DCSPATH/mut-position.py -d 1 -n 1 > sscs-muts.noSNP.txt

cat seq_both_sscs_clipped.bam.pileup.noSNP | python $DCSPATH/mut-position.py > seq_both_sscs_clipped.bam.pileup.noSNP.mutpos

rm *.sam

# Now go do the same thing for the directory containing only reverse mapping reads
cd ../reverse

# Rename each file to match input name for existing intersectbed script step
mv seq1rev.bam seq1.fq.smi.aln1.sort.bam
mv seq1rev.bam.bai seq1.fq.smi.aln1.sort.bam.bai

# Pickup existing script here. Does intersect bed step. Makes SSCS with standard criteria and re-aligns to genome.

intersectbed -abam seq1.fq.smi.aln1.sort.bam -b $BEDFILE > seq1-bed.fq.smi.aln1.sort.bam

python $DCSPATH/consensusMaker.py --readlength 84 --infile seq1-bed.fq.smi.aln1.sort.bam --tagfile seq1.tagcounts --fastqfile seq1_sscs.fastq --minmem 3 --maxmem 1000 --cutoff .9 --readnum 1 -p | bwa aln $FINALREF - > seq1_sscs.aln

cat seq1.tagcounts | python $DCSPATH/countField1.py 2| sort -k1,1n > seq1.tagstats

bwa samse $FINALREF seq1_sscs.aln seq1_sscs.fastq > seq1_sscs.sam

samtools view -Sbu seq1_sscs.sam | samtools sort - seq1_sscs.sort

samtools index seq1_sscs.sort.bam

# Because am only procesing read 1, I removed all the read 2 file steps and DCS steps. Normally rread 1 and read 2 files get merged. I took this step out and here rename the read1 files to become the seqboth files so names match for input in next steps.

mv  seq1_sscs.sort.bam  seq_both_sscs.bam
mv  seq1_sscs.sort.bam.bai  seq_both_sscs.bam.bai

# Back to normal script. Clip files. This is set to trim 12 from both ends.

java -jar -Xmx2g $PICARDPATH/AddOrReplaceReadGroups.jar INPUT=seq_both_sscs.bam OUTPUT=seq_both_sscs_readgroups.bam RGLB=UW RGPL=Illumina RGPU=ATATAT RGSM=default
samtools index seq_both_sscs_readgroups.bam

java -jar -Xmx8g $GATKPATH/GenomeAnalysisTK.jar -T ClipReads -I seq_both_sscs_readgroups.bam -o seq_both_sscs_clipped.bam -R $FINALREF --cyclesToTrim "73-84,1-12" --clipRepresentation HARDCLIP_BASES --fix_misencoded_quality_scores

samtools index seq_both_sscs_clipped.bam

# Final stats. I removed steps only relevent to DCS. Makes an SSCS pileup first:

samtools mpileup -B -d 500000 -f $FINALREF seq_both_sscs_clipped.bam > seq_both_sscs_clipped.bam.pileup

# Then take normal pileup and use specified file above to remove particular list of SNPs (For example all in P53/AR set with MAF >0.001)

cat seq_both_sscs_clipped.bam.pileup | bash $SNPPURGE > seq_both_sscs_clipped.bam.pileup.noSNP

# Below have changed -d from 20 to 1 (count all sites regardless of depth) and -C from 0.2 to 1 (turn off clonality cutoff). Default N filter is 5% (same). -u is counting uniques only (same)

# NOTE THAT AM USING A MODIFIED SCRIPT (count-muts.antiref.py) that will report out the reverse complement frequency and total bases sequended here.

cat seq_both_sscs_clipped.bam.pileup.noSNP | python $DCSPATH/count-muts.antiref.py -d 1 -C 1 -u > seq_both_sscs_clipped.bam.pileup.noSNP.countmuts.antiref

# Below have changed -d from 20 to 1 (count all sites regardless of depth). -C remains default of 1 (keep all % muts). N filter unchanged at 1 (no max). No -u (keep all, not just uniques) 

cat seq_both_sscs_clipped.bam.pileup.noSNP | python $DCSPATH/mut-position.py -d 1 -n 1 > sscs-muts.noSNP.txt

cat seq_both_sscs_clipped.bam.pileup.noSNP | python $DCSPATH/mut-position.py > seq_both_sscs_clipped.bam.pileup.noSNP.mutpos

rm *.sam











